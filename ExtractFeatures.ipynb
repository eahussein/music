{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import librosa as lb\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from  more_itertools import unique_everseen\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main flow of this code is further down the notebook. It requires a number of pre-defined functions and we could have saved all of these into a library and imported them, but just to be explicit they're presented here.\n",
    "\n",
    "First up, we'll need a function to split a song up into time chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split up a song into TIME chunks\n",
    "def splitT(mint,maxt,songdat):\n",
    "    splittime=[]\n",
    "    for i in range(mint,maxt):\n",
    "        splittime.append(songdat[:,i]) # first axis is freq, second axis is time. Return all freq for specific time range.\n",
    "    return (np.array(splittime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we'll need a function to split a song up into frequency chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split up a song into FREQ chunks\n",
    "def splitF(minv, maxv, songdat):\n",
    "    splitfreq = []\n",
    "    for i in range(minv,maxv):\n",
    "        splitfreq.append(songdat[i,:]) # first axis is freq, second axis is time. Return all time for specific freq range.\n",
    "    #print(splitfreq)\n",
    "    return (np.array(splitfreq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a master function to extract the machine learning features. This is the main function which gets features from the songs. Most values returned are the mean of the whole time series, hence '_a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_mean(song,sr,hop_length,n_fft):\n",
    "#     try:\n",
    "    print('>>> extracting features...')\n",
    "    y_harmonic, y_percussive = lb.effects.hpss(song) #split song into harmonic and percussive parts\n",
    "    stft_harmonic=lb.core.stft(y_harmonic, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "    stft_percussive=lb.core.stft(y_percussive, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "    #stft_all=lb.core.stft(song, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "    band_resolution=[5] #[5,25] Choose number of bands, do low and high resolution?\n",
    "    bands_dict=OrderedDict()\n",
    "\n",
    "    for no_bands in band_resolution:\n",
    "        bands=np.logspace(1.3,4,no_bands)/10 #note that as n_fft is 2050 (I've decided this is sensible resolution), bands/10=freq\n",
    "        bands_int=bands.astype(int)\n",
    "        bands_int_unique=list(unique_everseen(bands_int)) #removing double entries less than 100Hz, because logspace bunches up down there and we don't need doubles when rounding to the nearest 10 Hz.\n",
    "\n",
    "        for i in range(0,len(bands_int_unique)-1):\n",
    "\n",
    "            _h=lb.feature.rms(y=(splitF(bands_int_unique[i],bands_int_unique[i+1],stft_harmonic)))\n",
    "            _p=lb.feature.rms(y=(splitF(bands_int_unique[i],bands_int_unique[i+1],stft_percussive)))\n",
    "\n",
    "            #Calculate statistics for harmoinc and percussive over the time series.\n",
    "            rms_h=np.mean(np.abs(_h))\n",
    "            std_h=np.std(np.abs(_h))\n",
    "            skew_h=skew(np.mean(np.abs(_h), axis=0))  #skew of the time series (avg along freq axis, axis=0)\n",
    "            kurtosis_h=kurtosis(np.mean(np.abs(_h), axis=0), fisher=True, bias=True) #kurtosis of time series (avg along freq axis=0)\n",
    "\n",
    "            rms_p=np.mean(np.abs(_p))\n",
    "            std_p=np.std(np.abs(_p))\n",
    "            skew_p=skew(np.mean(np.abs(_p), axis=0))  #skew of the time series (avg along freq axis, axis=0)\n",
    "            kurtosis_p=kurtosis(np.mean(np.abs(_p), axis=0), fisher=True, bias=True) #kurtosis of time series (avg along freq axis=0)\n",
    "\n",
    "            #Append results to dict, with numbers as band labels\n",
    "            bands_dict.update({'{0}band_rms_h{1}'.format(no_bands,i):rms_h,'{0}band_rms_p{1}'.format(no_bands,i):rms_p})\n",
    "            bands_dict.update({'{0}band_std_h{1}'.format(no_bands,i):std_h,'{0}band_std_p{1}'.format(no_bands,i):std_p})\n",
    "            bands_dict.update({'{0}band_skew_h{1}'.format(no_bands,i):skew_h,'{0}band_skew_p{1}'.format(no_bands,i):skew_p})\n",
    "            bands_dict.update({'{0}band_kurtosis_h{1}'.format(no_bands,i):kurtosis_h,'{0}band_kurtosis_p{1}'.format(no_bands,i):kurtosis_p})\n",
    "\n",
    "    #stft=lb.feature.chroma_stft(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute a chromagram from a waveform or power spectrogram.\n",
    "    #stft_a=np.mean(stft[0])\n",
    "    #stft_std=np.std(stft[0])\n",
    "    #rmse=lb.feature.rms(y=song)\t#Compute root-mean-square (RMS) energy for each frame, either from the audio samples y or from a spectrogram S.\n",
    "    #rmse_a=np.mean(rmse)\n",
    "    #rmse_std=np.std(rmse)\n",
    "    rmseH=np.abs(lb.feature.rms(y=stft_harmonic))\t#Compute root-mean-square (RMS) energy for harmonic\n",
    "    rmseH_a=np.mean(rmseH)\n",
    "    rmseH_std=np.std(rmseH)\n",
    "    rmseH_skew=skew(np.mean(rmseH, axis=0))\n",
    "    rmseH_kurtosis=kurtosis(np.mean(rmseH, axis=0), fisher=True, bias=True)\n",
    "\n",
    "    rmseP=np.abs(lb.feature.rms(y=stft_percussive))\t#Compute root-mean-square (RMS) energy for percussive\n",
    "    rmseP_a=np.mean(rmseP)\n",
    "    rmseP_std=np.std(rmseP)\n",
    "    rmseP_skew=skew(np.mean(rmseP, axis=0))\n",
    "    rmseP_kurtosis=kurtosis(np.mean(rmseP, axis=0), fisher=True, bias=True)\n",
    "\n",
    "    centroid=lb.feature.spectral_centroid(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute the spectral centroid.\n",
    "    centroid_a=np.mean(centroid)\n",
    "    centroid_std=np.std(centroid)\n",
    "    bw=lb.feature.spectral_bandwidth(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute p’th-order spectral bandwidth:\n",
    "    bw_a=np.mean(bw)\n",
    "    bw_std=np.std(bw)\n",
    "    contrast=lb.feature.spectral_contrast(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute spectral contrast [R16]\n",
    "    contrast_a=np.mean(contrast)\n",
    "    contrast_std=np.std(contrast)\n",
    "    polyfeat=lb.feature.poly_features(y_harmonic, sr, n_fft=n_fft, hop_length=hop_length)\t#Get coefficients of fitting an nth-order polynomial to the columns of a spectrogram.\n",
    "    polyfeat_a=np.mean(polyfeat[0])\n",
    "    polyfeat_std=np.std(polyfeat[0])\n",
    "    tonnetz=lb.feature.tonnetz(librosa.effects.harmonic(y_harmonic), sr)\t#Computes the tonal centroid features (tonnetz), following the method of [R17].\n",
    "    tonnetz_a=np.mean(tonnetz)\n",
    "    tonnetz_std=np.std(tonnetz)\n",
    "    zcr=lb.feature.zero_crossing_rate(song, sr, hop_length=hop_length)  #zero crossing rate\n",
    "    zcr_a=np.mean(zcr)\n",
    "    zcr_std=np.std(zcr)\n",
    "    onset_env=lb.onset.onset_strength(y_percussive, sr=sr)\n",
    "    onset_a=np.mean(onset_env)\n",
    "    onset_std=np.std(onset_env)\n",
    "    D = librosa.stft(song)\n",
    "    times = librosa.frames_to_time(np.arange(D.shape[1])) #not returned, but could be if you want to plot things as a time series\n",
    "    bpm,beats=lb.beat.beat_track(y=y_percussive, sr=sr, onset_envelope=onset_env, units='time')\n",
    "    beats_a=np.mean(beats)\n",
    "    beats_std=np.std(beats)\n",
    "\n",
    "    features_dict=OrderedDict({'rmseP_a':rmseP_a,'rmseP_std':rmseP_std,'rmseH_a':rmseH_a,'rmseH_std':rmseH_std,'centroid_a':centroid_a,'centroid_std':centroid_std,'bw_a':bw_a,'bw_std':bw_std,'contrast_a':contrast_a,'contrast_std':contrast_std,'polyfeat_a':polyfeat_a,'polyfeat_std':polyfeat_std,'tonnetz_a':tonnetz_a,'tonnetz_std':tonnetz_std,'zcr_a':zcr_a,'zcr_std':zcr_std,'onset_a':onset_a,'onset_std':onset_std,'bpm':bpm, 'rmseP_skew':rmseP_skew, 'rmseP_kurtosis':rmseP_kurtosis, 'rmseH_skew':rmseH_skew, 'rmseH_kurtosis':rmseH_kurtosis})\n",
    "    combine_features={**features_dict,**bands_dict}\n",
    "    print('>>> features extracted successfully')\n",
    "    return combine_features\n",
    "\n",
    "#     except:\n",
    "#         print('.'*20+'FAILED'+'.'*20)\n",
    "#         print('.'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a function to load the songs into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load music function, accepts any format i've encountered: mp3,wav,wma bla bla\n",
    "def load_music(songname1,songpath1):\n",
    "    try:\n",
    "        print('loading the song: {0} ......... located here: {1} '.format(songname1, songpath1))\n",
    "        songdata1, sr1 = lb.load(songpath1) # librosa library used to grab song data and sample rate\n",
    "        print ('done........ '+songname1)\n",
    "        return [songname1,songdata1,sr1]\n",
    "    except: # the song could be corrupt or you could be trying to load something which isn't a song\n",
    "        print('..............................FAILED...............................')\n",
    "        print(songpath1)\n",
    "        print('...................................................................')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for saving the python dictionaries to disk\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the python dictionaries from disk\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a grid-plot to test anything out, this will help. \n",
    "# Although I've made sure get_features returns only averaged values, not time-series data, so meh.\n",
    "def gridplot(data_dict,feature,size,N,ind):\n",
    "    f, axarr = plt.subplots(size, size, sharey=True)\n",
    "    i=0\n",
    "    j=0\n",
    "    for key in data_dict:\n",
    "        #print (i,j)\n",
    "        axarr[i,j].plot(np.convolve(data_dict[key][feature][ind],np.ones((N,))/N, mode='valid'))\n",
    "        axarr[i, j].set_title(key[:3])\n",
    "        if j==size-1: i+=1\n",
    "        j=0 if j==size-1 else j+1\n",
    "    for i in range(1,size,1):\n",
    "        plt.setp([a.get_yticklabels() for a in axarr[:, i]], visible=False)\n",
    "    plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "This is where we actually start to write the main program...\n",
    "\n",
    "Let's make a note of the start time for loading our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_load=time.time() # we're going to want know how long this takes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a computationally expensive routine so we should use multiprocessing. Let's work out how many cores are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have 12 cores available to do your bidding...\n"
     ]
    }
   ],
   "source": [
    "num_workers = multiprocessing.cpu_count() \n",
    "print('you have {0} cores available to do your bidding...'.format(num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft1=2050 # important parameter here; this is the size of the fft window. these are sensible values\n",
    "hop_length1=441 # n_fft/5 is a sensible value. Too large and you don't sample properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a temporary database for the songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create song database, songdb:\n",
    "songname_tmp=[]\n",
    "songpath_tmp=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is set to start reading in the song names. So we need to tell the program where to find them, i.e. the name of the artist directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='free_music'\n",
    "filename = librosa.ex('trumpet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output feature file will have the same name with the suffix \"_data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile=str(path)+'_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of songs by looping through the directory contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMBForst_Forest (ID 0100)_BSB.wav\n"
     ]
    }
   ],
   "source": [
    "for song in os.listdir(path):\n",
    "    print (song)\n",
    "    songname_tmp.append(song)\n",
    "    songpath_tmp.append(path+'/'+song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "songname=songname_tmp #i'm just reassigning the name incase of tests with commented out lines...\n",
    "songpath=songpath_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the song data is a slow process, so we'll parallelize it over multiple processors. A **starmap** is a way to pass multiple arguments to a single function using multiple processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading songs...\n",
      "AMBForst_Forest (ID 0100)_BSB.wav\n",
      "free_music/AMBForst_Forest (ID 0100)_BSB.wav\n",
      "\n",
      "loading the song: AMBForst_Forest (ID 0100)_BSB.wav ......... located here: free_music/AMBForst_Forest (ID 0100)_BSB.wav \n",
      "done........ AMBForst_Forest (ID 0100)_BSB.wav\n",
      ">>> finished loading songs into songdb\n"
     ]
    }
   ],
   "source": [
    "print('>>> loading songs...')\n",
    "\n",
    "# =====\n",
    "# Parallel version:\n",
    "#with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "#    songdb=pool.starmap(load_music,zip(songname,songpath))\n",
    "#    pool.close()\n",
    "#    pool.join()\n",
    "\n",
    "# Serial version:\n",
    "songdb=[]\n",
    "for i in range(0, len(songname)):\n",
    "    print(songname[i])\n",
    "    print(songpath[i])\n",
    "    print()\n",
    "    \n",
    "    songdb.append(load_music(songname[i], songpath[i]))\n",
    "# =====\n",
    "\n",
    "print('>>> finished loading songs into songdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a quick check to remove any entries where loading may have failed for any reason (rare cases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loaded 1 songs into memory\n"
     ]
    }
   ],
   "source": [
    "print ('>>> loaded {0} songs into memory'.format(len(songdb)))\n",
    "songdb=[x for x in songdb if x is not None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[] # text\n",
    "song_data=[] # list of numbers\n",
    "song_sr=[]   # sample rate\n",
    "\n",
    "for song1 in songdb: \n",
    "    song_name.append(song1[0])\n",
    "    song_data.append(song1[1])\n",
    "    song_sr.append(song1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the last step in loading the songs, so let's check how long it took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading the songs into memory took 2.7637243270874023 seconds\n"
     ]
    }
   ],
   "source": [
    "stop_load=time.time()\n",
    "\n",
    "loadtime = stop_load - start_load\n",
    "print('>>> loading the songs into memory took {0} seconds'.format(loadtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll extract the machine learning features from the songs, so let's make a note of our start time for this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_feat = time.time() # note the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the features we use the **get_features_mean** function defined earlier. Again this can be slow so we're spreading it over multiple processors.\n",
    "\n",
    "**Note:** you will get a string of deprecation errors, you can safely ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Data is all ready, now extracting features from the songs...\n",
      ">>> extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-137-a6ffc4aa0dc4>:56: FutureWarning: Pass y=[ 0.00078168  0.00011291 -0.00219711 ...  0.0024626   0.00671026\n",
      "  0.        ], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  centroid=lb.feature.spectral_centroid(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute the spectral centroid.\n",
      "<ipython-input-137-a6ffc4aa0dc4>:59: FutureWarning: Pass y=[ 0.00078168  0.00011291 -0.00219711 ...  0.0024626   0.00671026\n",
      "  0.        ], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  bw=lb.feature.spectral_bandwidth(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute p’th-order spectral bandwidth:\n",
      "<ipython-input-137-a6ffc4aa0dc4>:62: FutureWarning: Pass y=[ 0.00078168  0.00011291 -0.00219711 ...  0.0024626   0.00671026\n",
      "  0.        ], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  contrast=lb.feature.spectral_contrast(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute spectral contrast [R16]\n",
      "<ipython-input-137-a6ffc4aa0dc4>:65: FutureWarning: Pass y=[-0.00061502 -0.00053565 -0.00096582 ...  0.00136138  0.00322495\n",
      " -0.00037054], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  polyfeat=lb.feature.poly_features(y_harmonic, sr, n_fft=n_fft, hop_length=hop_length)\t#Get coefficients of fitting an nth-order polynomial to the columns of a spectrogram.\n",
      "<ipython-input-137-a6ffc4aa0dc4>:68: FutureWarning: Pass y=[-0.00107293 -0.00098144 -0.00087452 ...  0.00022544  0.00127256\n",
      " -0.00050466], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  tonnetz=lb.feature.tonnetz(librosa.effects.harmonic(y_harmonic), sr)\t#Computes the tonal centroid features (tonnetz), following the method of [R17].\n",
      "<ipython-input-137-a6ffc4aa0dc4>:71: FutureWarning: Pass frame_length=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  zcr=lb.feature.zero_crossing_rate(song, sr, hop_length=hop_length)  #zero crossing rate\n",
      "<ipython-input-137-a6ffc4aa0dc4>:74: FutureWarning: Pass y=[ 0.00139669  0.00064856 -0.00123129 ...  0.00110122  0.00348531\n",
      "  0.00037054] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  onset_env=lb.onset.onset_strength(y_percussive, sr=sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> features extracted successfully\n",
      ">>> extracted 1 features from all songs\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Data is all ready, now extracting features from the songs...\")\n",
    "\n",
    "# =====\n",
    "# Parallel version:\n",
    "#with multiprocessing.Pool(processes=num_workers,maxtasksperchild=1) as pool:\n",
    "#    res=pool.starmap(get_features_mean,zip(song_data,song_sr,itertools.repeat(hop_length1),itertools.repeat(n_fft1)))\n",
    "#    pool.close()\n",
    "#    pool.join()\n",
    "\n",
    "# Serial version:\n",
    "res=[]\n",
    "for i in range(0,len(song_data)):\n",
    "    res.append(get_features_mean(song_data[i], song_sr[i], hop_length1, n_fft1))\n",
    "\n",
    "# =====\n",
    "\n",
    "print('>>> extracted {0} features from all songs'.format(len(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've got the features we concatenate them all into a single dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> concatenating results into a massive dictionary...\n"
     ]
    }
   ],
   "source": [
    "# concatenate each songs features (res) into dictionary\n",
    "print('>>> concatenating results into a massive dictionary...')\n",
    "\n",
    "data_dict_mean={}\n",
    "for i in range(0,len(songdb)):\n",
    "    data_dict_mean.update({song_name[i]:res[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AMBForst_Forest (ID 0100)_BSB.wav': {'rmseP_a': 0.11515416, 'rmseP_std': 0.11108603, 'rmseH_a': 0.06898209, 'rmseH_std': 0.10873733, 'centroid_a': 2670.9216336968484, 'centroid_std': 761.9857904747197, 'bw_a': 2236.4312818223993, 'bw_std': 290.3332567420034, 'contrast_a': 18.25936548874523, 'contrast_std': 8.344514563891384, 'polyfeat_a': -1.2968211861009747e-05, 'polyfeat_std': 4.936520110586135e-06, 'tonnetz_a': -0.0030104394795337115, 'tonnetz_std': 0.07182264646223933, 'zcr_a': 0.19776524688855185, 'zcr_std': 0.10311405333884556, 'onset_a': 1.2852021, 'onset_std': 0.5186931, 'bpm': 123.046875, 'rmseP_skew': array([0., 0., 0., 0., 0., 0.], dtype=float32), 'rmseP_kurtosis': array([-3., -3., -3., -3., -3., -3.], dtype=float32), 'rmseH_skew': array([0., 0., 0., 0., 0., 0.], dtype=float32), 'rmseH_kurtosis': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_rms_h0': 0.46638286, '5band_rms_p0': 0.30210438, '5band_std_h0': 0.2728199, '5band_std_p0': 0.07951982, '5band_skew_h0': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_skew_p0': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_kurtosis_h0': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_kurtosis_p0': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_rms_h1': 0.3614107, '5band_rms_p1': 0.16895112, '5band_std_h1': 0.27823895, '5band_std_p1': 0.05113307, '5band_skew_h1': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_skew_p1': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_kurtosis_h1': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_kurtosis_p1': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_rms_h2': 0.07344287, '5band_rms_p2': 0.07431987, '5band_std_h2': 0.041379027, '5band_std_p2': 0.03320748, '5band_skew_h2': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_skew_p2': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_kurtosis_h2': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_kurtosis_p2': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_rms_h3': 0.05337482, '5band_rms_p3': 0.12335863, '5band_std_h3': 0.07086258, '5band_std_p3': 0.11954814, '5band_skew_h3': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_skew_p3': array([0., 0., 0., 0., 0., 0.], dtype=float32), '5band_kurtosis_h3': array([-3., -3., -3., -3., -3., -3.], dtype=float32), '5band_kurtosis_p3': array([-3., -3., -3., -3., -3., -3.], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "print(data_dict_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and that's it, really. Now we can just check our features and save them for use with our machine learning algorithms later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The features extracted from the songs are: \n",
      "dict_keys(['rmseP_a', 'rmseP_std', 'rmseH_a', 'rmseH_std', 'centroid_a', 'centroid_std', 'bw_a', 'bw_std', 'contrast_a', 'contrast_std', 'polyfeat_a', 'polyfeat_std', 'tonnetz_a', 'tonnetz_std', 'zcr_a', 'zcr_std', 'onset_a', 'onset_std', 'bpm', 'rmseP_skew', 'rmseP_kurtosis', 'rmseH_skew', 'rmseH_kurtosis', '5band_rms_h0', '5band_rms_p0', '5band_std_h0', '5band_std_p0', '5band_skew_h0', '5band_skew_p0', '5band_kurtosis_h0', '5band_kurtosis_p0', '5band_rms_h1', '5band_rms_p1', '5band_std_h1', '5band_std_p1', '5band_skew_h1', '5band_skew_p1', '5band_kurtosis_h1', '5band_kurtosis_p1', '5band_rms_h2', '5band_rms_p2', '5band_std_h2', '5band_std_p2', '5band_skew_h2', '5band_skew_p2', '5band_kurtosis_h2', '5band_kurtosis_p2', '5band_rms_h3', '5band_rms_p3', '5band_std_h3', '5band_std_p3', '5band_skew_h3', '5band_skew_p3', '5band_kurtosis_h3', '5band_kurtosis_p3'])\n",
      "----------\n",
      ">>> Saving dictionary to disk...\n",
      "----------\n",
      "loading time: 2.7696914672851562 seconds\n",
      "feature extraction time: 17.239344835281372 seconds\n",
      "total time: 20.00903630256653 seconds\n",
      "----------\n",
      ">>> Finished\n"
     ]
    }
   ],
   "source": [
    "# print features to screen to check\n",
    "print('>>> The features extracted from the songs are: ')\n",
    "print(res[0].keys())\n",
    "\n",
    "print(\"----------\")\n",
    "print('>>> Saving dictionary to disk...')\n",
    "save_obj(data_dict_mean,savefile)\n",
    "\n",
    "end_feat=time.time() # note finish time\n",
    "print(\"----------\")\n",
    "print(\"loading time: {0} seconds\".format(start_feat-start_load))\n",
    "print(\"feature extraction time: {0} seconds\".format(end_feat-start_feat))\n",
    "print(\"total time: {0} seconds\".format(end_feat-start_load))\n",
    "print(\"----------\")\n",
    "print('>>> Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- add more music to the \"free_music\" folder, and run this notebook again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
